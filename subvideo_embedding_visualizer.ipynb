{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/rob/miniconda3/envs/VLM_MILES/lib/python3.9/site-packages (3.5.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/rob/miniconda3/envs/VLM_MILES/lib/python3.9/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/rob/miniconda3/envs/VLM_MILES/lib/python3.9/site-packages (from matplotlib) (1.23.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/rob/miniconda3/envs/VLM_MILES/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/rob/miniconda3/envs/VLM_MILES/lib/python3.9/site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/rob/miniconda3/envs/VLM_MILES/lib/python3.9/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/rob/miniconda3/envs/VLM_MILES/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/rob/miniconda3/envs/VLM_MILES/lib/python3.9/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/rob/miniconda3/envs/VLM_MILES/lib/python3.9/site-packages (from matplotlib) (4.35.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/rob/miniconda3/envs/VLM_MILES/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: plotly in /home/rob/miniconda3/envs/VLM_MILES/lib/python3.9/site-packages (5.10.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/rob/miniconda3/envs/VLM_MILES/lib/python3.9/site-packages (from plotly) (8.0.1)\n",
      "Requirement already satisfied: sklearn in /home/rob/miniconda3/envs/VLM_MILES/lib/python3.9/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /home/rob/miniconda3/envs/VLM_MILES/lib/python3.9/site-packages (from sklearn) (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/rob/miniconda3/envs/VLM_MILES/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.23.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/rob/miniconda3/envs/VLM_MILES/lib/python3.9/site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /home/rob/miniconda3/envs/VLM_MILES/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/rob/miniconda3/envs/VLM_MILES/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.9.0)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "!pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "!pip install plotly\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "\n",
    "!pip install sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Dataset and VLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.moma.momaapi.lookup._read_anns() took 1.106520175933838 sec\n",
      "dataset.moma.momaapi.statistics._read_statistics() took 0.0006163120269775391 sec\n"
     ]
    }
   ],
   "source": [
    "from similarity_metrics import Similarity\n",
    "from dataset import DatasetHandler\n",
    "    \n",
    "if True:\n",
    "    dataset = DatasetHandler(\"moma_act\", \"test\", 10)\n",
    "\n",
    "if False:\n",
    "    dataset = DatasetHandler(\"moma_sact\", \"test\", 10)\n",
    "    \n",
    "if False:\n",
    "    dataset = DatasetHandler(\"kinetics_100\", \"test\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######USING ATTENTION STYLE:  frozen-in-time\n"
     ]
    }
   ],
   "source": [
    "ENV = os.environ[\"CONDA_DEFAULT_ENV\"]\n",
    "if ENV == \"VLM_MILES\":\n",
    "    from MILES.wrapper import MILES_SimilarityVLM\n",
    "    vlm = MILES_SimilarityVLM()\n",
    "else:\n",
    "    raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifier import SubVideoAverageFewShotClassifier\n",
    "classifier = SubVideoAverageFewShotClassifier(vlm, subvideo_segment_duration=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set fixed order for category names, paths and associated embeddings\n",
    "category_names = list(dataset.data_dict.keys())\n",
    "category_paths = [dataset.data_dict[name] for name in category_names]\n",
    "\n",
    "text_embeds_per_category = [vlm.get_text_embeds(name) for name in category_names]\n",
    "subvid_embeds_per_category = [\n",
    "    [\n",
    "        classifier.get_subvideo_embeds(path)\n",
    "        for path in paths\n",
    "    ]\n",
    "    for paths in category_paths\n",
    "]\n",
    "vid_embeds_per_category = [\n",
    "    [\n",
    "        vlm.get_video_embeds(path)\n",
    "        for path in paths\n",
    "    ]\n",
    "    for paths in category_paths\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beauty salon service</th>\n",
       "      <th>drive-thru ordering</th>\n",
       "      <th>physical therapy</th>\n",
       "      <th>reception service</th>\n",
       "      <th>table tennis game</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.583817</td>\n",
       "      <td>0.70201</td>\n",
       "      <td>0.905029</td>\n",
       "      <td>0.811988</td>\n",
       "      <td>0.731826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.812259</td>\n",
       "      <td>0.681857</td>\n",
       "      <td>0.784008</td>\n",
       "      <td>0.803887</td>\n",
       "      <td>0.576599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.866064</td>\n",
       "      <td>0.656108</td>\n",
       "      <td>0.825429</td>\n",
       "      <td>0.779539</td>\n",
       "      <td>0.812658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.781305</td>\n",
       "      <td>0.705206</td>\n",
       "      <td>0.673036</td>\n",
       "      <td>0.88393</td>\n",
       "      <td>0.865076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.48188</td>\n",
       "      <td>0.928694</td>\n",
       "      <td>0.808298</td>\n",
       "      <td>0.715765</td>\n",
       "      <td>0.697708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.743071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.831335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.935701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.916482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    beauty salon service drive-thru ordering physical therapy  \\\n",
       "0               0.583817             0.70201         0.905029   \n",
       "1               0.812259            0.681857         0.784008   \n",
       "2               0.866064            0.656108         0.825429   \n",
       "3               0.781305            0.705206         0.673036   \n",
       "4                0.48188            0.928694         0.808298   \n",
       "..                   ...                 ...              ...   \n",
       "100                  NaN                 NaN              NaN   \n",
       "101                  NaN                 NaN              NaN   \n",
       "102                  NaN                 NaN              NaN   \n",
       "103                  NaN                 NaN              NaN   \n",
       "104                  NaN                 NaN              NaN   \n",
       "\n",
       "    reception service table tennis game  \n",
       "0            0.811988          0.731826  \n",
       "1            0.803887          0.576599  \n",
       "2            0.779539          0.812658  \n",
       "3             0.88393          0.865076  \n",
       "4            0.715765          0.697708  \n",
       "..                ...               ...  \n",
       "100               NaN          0.701937  \n",
       "101               NaN          0.743071  \n",
       "102               NaN          0.831335  \n",
       "103               NaN          0.935701  \n",
       "104               NaN          0.916482  \n",
       "\n",
       "[105 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beauty salon service</th>\n",
       "      <th>drive-thru ordering</th>\n",
       "      <th>physical therapy</th>\n",
       "      <th>reception service</th>\n",
       "      <th>table tennis game</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.740081</td>\n",
       "      <td>0.743451</td>\n",
       "      <td>0.722313</td>\n",
       "      <td>0.769837</td>\n",
       "      <td>0.841255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   beauty salon service  drive-thru ordering  physical therapy  \\\n",
       "0              0.740081             0.743451          0.722313   \n",
       "\n",
       "   reception service  table tennis game  \n",
       "0           0.769837           0.841255  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intra_subvid_similarity = [\n",
    "    [\n",
    "        np.mean(vlm.default_similarity_metric()(np.array(subvid_embeds), np.array(subvid_embeds)))\n",
    "        for subvid_embeds in category_subvid_embeds\n",
    "    ]\n",
    "    for category_subvid_embeds in subvid_embeds_per_category\n",
    "]\n",
    "\n",
    "mean_category_intra_subvid_similarity = [\n",
    "    np.mean(category_intra_subvid_similarity)\n",
    "    for category_intra_subvid_similarity in intra_subvid_similarity\n",
    "]\n",
    "\n",
    "temp = pd.DataFrame(columns=category_names, index=range(max(*[len(paths) for paths in category_paths])))\n",
    "for i, category_intra_subvid_similarity in enumerate(intra_subvid_similarity):\n",
    "    for j, video_intra_subvid_similarity in enumerate(category_intra_subvid_similarity):\n",
    "        temp.iloc[j, i] = video_intra_subvid_similarity\n",
    "display(temp)\n",
    "\n",
    "pd.DataFrame([mean_category_intra_subvid_similarity], columns=category_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute T-SNE Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rob/miniconda3/envs/VLM_MILES/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py:800: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "/home/rob/miniconda3/envs/VLM_MILES/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py:810: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Stack embeddings to perform T-SNE over all together\n",
    "\n",
    "stacked_embeddings = []\n",
    "text_stacked_indices = []\n",
    "vid_stacked_indices = []\n",
    "subvid_stacked_indices = []\n",
    "\n",
    "next_index = 0\n",
    "for name, text_embed, paths, vid_embeds_per_path, subvid_embeds_per_path in zip(category_names, text_embeds_per_category, category_paths, vid_embeds_per_category, subvid_embeds_per_category):\n",
    "    stacked_embeddings.append(text_embed)\n",
    "    text_stacked_indices.append(next_index)\n",
    "    next_index += 1\n",
    "    \n",
    "    stacked_embeddings += vid_embeds_per_path\n",
    "    vid_stacked_indices.append([next_index + i for i in range(len(vid_embeds_per_path))])\n",
    "    next_index += len(vid_embeds_per_path)\n",
    "    \n",
    "    subvid_stacked_indices.append([])\n",
    "    for path, subvid_embeds in zip(paths, subvid_embeds_per_path):\n",
    "        stacked_embeddings += subvid_embeds\n",
    "        subvid_stacked_indices[-1].append([next_index + i for i in range(len(subvid_embeds))])\n",
    "        next_index += len(subvid_embeds)\n",
    "        \n",
    "stacked_embeddings = np.array(stacked_embeddings)\n",
    "\n",
    "\n",
    "\n",
    "if vlm.default_similarity_metric() is Similarity.COSINE:\n",
    "    sklearn_metric = \"cosine\"\n",
    "elif vlm.default_similarity_metric() is Similarity.DOT:\n",
    "    # NOTE: This is imperfect. No distance metric can match dot-product ordering without violating triangle inequality\n",
    "    # (For any 2 vectors which aren't directly opposite each other, a third vector exists with arbitrarily-high similarity to both)\n",
    "    sklearn_metric = lambda a, b: math.exp(-Similarity.DOT(a[None, :], b[None, :]))\n",
    "else:\n",
    "    raise ValueError(\"Unknown equivalent sklearn metric name\")\n",
    "\n",
    "sne_embeddings = TSNE(n_components=2, metric=sklearn_metric).fit_transform(stacked_embeddings)\n",
    "\n",
    "\n",
    "\n",
    "# Unstack SNE embeddings into original fixed order of embeddings\n",
    "text_sne_embeds_per_category = [\n",
    "    sne_embeddings[text_stacked_index]\n",
    "    for text_stacked_index in text_stacked_indices\n",
    "]\n",
    "vid_sne_embeds_per_category = [\n",
    "    [\n",
    "        sne_embeddings[vid_stacked_index]\n",
    "        for vid_stacked_index in category_vid_stacked_indices\n",
    "    ]\n",
    "    for category_vid_stacked_indices in vid_stacked_indices\n",
    "]\n",
    "subvid_sne_embeds_per_category = [\n",
    "    [\n",
    "        [\n",
    "            sne_embeddings[subvid_stacked_index]\n",
    "            for subvid_stacked_index in path_subvid_stacked_indices\n",
    "        ]\n",
    "        for path_subvid_stacked_indices in category_subvid_stacked_indices\n",
    "    ]\n",
    "    for category_subvid_stacked_indices in subvid_stacked_indices\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive SNE Embedding Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class-specific plots\n",
    "# Subplot for each video's subvideo path, plotted against all class text embeddings\n",
    "PLOT_DIR = f\"subvideo_visualizations/subvideo_plots.{vlm.__class__.__name__}.{classifier.subvideo_segment_duration}s_segments.{dataset.id()}\"\n",
    "os.makedirs(PLOT_DIR, exist_ok=True)\n",
    "\n",
    "for cat_name, text_sne_embed, path_per_vid, vid_sne_embeds_per_vid, subvid_sne_embeds_per_vid in zip(category_names, text_sne_embeds_per_category, category_paths, vid_sne_embeds_per_category, subvid_sne_embeds_per_category):\n",
    "    SUBPLOT_COUNT = len(path_per_vid)\n",
    "    \n",
    "    N_COLS = 4\n",
    "    N_ROWS = math.ceil(SUBPLOT_COUNT / N_COLS)\n",
    "    FIG_WIDTH = 1600\n",
    "\n",
    "    fig = make_subplots(rows=N_ROWS, cols=N_COLS,\n",
    "                        vertical_spacing=0.2 / N_ROWS, horizontal_spacing=0.2 / N_COLS,\n",
    "                        subplot_titles=[path.split(\"/\")[-1] for path in path_per_vid[:SUBPLOT_COUNT]])\n",
    "    for i in range(SUBPLOT_COUNT):\n",
    "        path = path_per_vid[i]\n",
    "        subvid_sne_embeds = np.array(subvid_sne_embeds_per_vid[i])\n",
    "        vid_sne_embed = vid_sne_embeds_per_vid[i]\n",
    "        \n",
    "        # Reset color palette\n",
    "        palette = itertools.cycle(px.colors.qualitative.D3)\n",
    "        \n",
    "        # Incorrect class text embeds\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                mode=\"markers\",\n",
    "                x=[other_text_sne_embed[0] for other_cat_name, other_text_sne_embed in zip(category_names, text_sne_embeds_per_category) if other_cat_name != cat_name],\n",
    "                y=[other_text_sne_embed[1] for other_cat_name, other_text_sne_embed in zip(category_names, text_sne_embeds_per_category) if other_cat_name != cat_name],\n",
    "                text=[other_cat_name + \" (incorrect)\" for other_cat_name in category_names if other_cat_name != cat_name],\n",
    "                hovertemplate=\"%{text}<extra></extra>\",\n",
    "                marker_size=20,\n",
    "                marker_opacity=0.8,\n",
    "                marker_color=next(palette)\n",
    "            ),\n",
    "            row = i // N_COLS + 1,\n",
    "            col = i % N_COLS + 1\n",
    "        )\n",
    "        \n",
    "        # Subvideo embed path\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                mode=\"markers+lines\",\n",
    "                x=subvid_sne_embeds[:, 0],\n",
    "                y=subvid_sne_embeds[:, 1],\n",
    "                text=[f\"Subvideo Embed {i}\" for i in range(len(subvid_sne_embeds))],\n",
    "                hovertemplate=\"%{text}<extra></extra>\",\n",
    "                marker_size=10,\n",
    "                marker_opacity=0.8,\n",
    "                marker_color=next(palette)\n",
    "            ),\n",
    "            row = i // N_COLS + 1,\n",
    "            col = i % N_COLS + 1\n",
    "        )\n",
    "        \n",
    "        # Video Embed\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                mode=\"markers\",\n",
    "                x=[vid_sne_embed[0]],\n",
    "                y=[vid_sne_embed[1]],\n",
    "                text=[f\"Full Video Embed\"],\n",
    "                hovertemplate=\"%{text}<extra></extra>\",\n",
    "                marker_size=10,\n",
    "                marker_opacity=0.8,\n",
    "                marker_color=next(palette)\n",
    "            ),\n",
    "            row = i // N_COLS + 1,\n",
    "            col = i % N_COLS + 1\n",
    "        )\n",
    "        \n",
    "        # Plot correct class text embed\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                mode=\"markers\",\n",
    "                x=text_sne_embed[:1], y=text_sne_embed[1:],\n",
    "                text=[cat_name + \" (correct)\"],\n",
    "                hovertemplate=\"%{text}<extra></extra>\",\n",
    "                marker_size=20,\n",
    "                marker_opacity=0.8,\n",
    "                marker_color=next(palette)\n",
    "            ),\n",
    "            row = i // N_COLS + 1,\n",
    "            col = i % N_COLS + 1\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "    fig.update_layout(width=FIG_WIDTH, height=FIG_WIDTH / N_COLS * N_ROWS, showlegend=False, title=cat_name)\n",
    "\n",
    "    fig.write_html(f\"{PLOT_DIR}/{cat_name.replace(' ', '_')}.html\")\n",
    "    fig.show()\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('VLM_MILES')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aa12131d24cc94205087ad381a7dfdae34f6e827b859c030f23450f0750c1ff3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
